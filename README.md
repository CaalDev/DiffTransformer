# DiffTransformer
# Differential Transformer for Hallucination Mitigation


![Python](https://img.shields.io/badge/python-3.9%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1AN4GwY19-fQUqQvBwzcWgXdAqkF2sh-P/view?usp=drive_link)

Proyecto acad√©mico que implementa y eval√∫a el mecanismo de **atenci√≥n diferencial** (Differential Attention) propuesto en el paper:

> **"Differential Transformer"** ‚Äî Ye et al., 2024  
> Paper: https://arxiv.org/abs/2410.05258

Este trabajo demuestra c√≥mo la atenci√≥n diferencial reduce la asignaci√≥n de atenci√≥n a contexto irrelevante ("ruido") y mitiga alucinaciones en tareas de *question answering* con contextos largos.

---

### Equipo
- Maria Liliana Parra Osorno  
- Daniel Casta√±eda Montenegro  
- Carlos Andr√©s Aguirre L√≥pez  

**Profesor:** Alcides Montoya Ca√±ola  
**Universidad Nacional de Colombia - Medell√≠n**  
**Noviembre 2025**

---

### Objetivo
Implementar y comparar el **Differential Transformer** frente al Transformer est√°ndar, evaluando:
- Reducci√≥n de alucinaciones en tareas QA
- Mejor manejo de contextos largos
- Emergencia de patrones de atenci√≥n m√°s esparsos y focalizados
- Disminuci√≥n de outliers en activaciones

---

### Concepto Clave: Atenci√≥n Diferencial

> Es como **aud√≠fonos con cancelaci√≥n de ruido**

```math
\text{DiffAttn}(Q,K,V) = \left( \text{softmax}\left(\frac{Q_1 K_1^T}{\sqrt{d}}\right) - \lambda \cdot \text{softmax}\left(\frac{Q_2 K_2^T}{\sqrt{d}}\right) \right) V
```

- Primer t√©rmino: Captura se√±al + ruido
- Segundo t√©rmino: Captura principalmente ruido
- Œª (aprendible): Controla la intensidad de cancelaci√≥n
- Resultado: Se amplifica la se√±al relevante y se suprime el ruido

## üìë Estructura de Proyecto de Tesis

Este √≠ndice detalla un enfoque robusto y experimental para la mitigaci√≥n de alucinaciones en modelos de lenguaje utilizando el mecanismo de **Atenci√≥n Diferencial (DiffAttn)**.

| Secci√≥n | T√≠tulo de la Secci√≥n | Descripci√≥n/Contenido Clave |
| :--- | :--- | :--- |
| **1.** | **Introducci√≥n y Objetivos** | Contexto del problema de la alucinaci√≥n en LLMs, relevancia de la mitigaci√≥n, y presentaci√≥n de los objetivos espec√≠ficos del proyecto. |
| **2.** | **Marco Te√≥rico** | Fundamentos del mecanismo de **Atenci√≥n Est√°ndar (Transformer)** y la justificaci√≥n te√≥rica del mecanismo **Atenci√≥n Diferencial (DiffAttn)** como filtro de ruido y sesgos. |
| **3.** | **Configuraci√≥n del Entorno** | Detalles de la infraestructura de hardware (ej. uso de **GPU A100**), versiones de frameworks (**PyTorch/TensorFlow**), y configuraci√≥n del entorno de desarrollo. |
| **4.** | **Atenci√≥n Est√°ndar (Baseline)** | Implementaci√≥n de un modelo **Transformer est√°ndar (Baseline)** y descripci√≥n del conjunto de datos inicial para establecer la m√©trica de rendimiento a superar. |
| **5.** | **Atenci√≥n Diferencial (DiffAttn)** | Implementaci√≥n y detalles t√©cnicos del mecanismo **DiffAttn** (incluyendo las dos cabezas de atenci√≥n y el factor de cancelaci√≥n $\lambda$) dentro del modelo Transformer. |
| **6.** | **Experimentos Sint√©ticos** | Dise√±o de pruebas controladas para evaluar la robustez del modelo al **ruido expl√≠cito o *inputs* contradictorios**, demostrando la capacidad de cancelaci√≥n de $\lambda$. |
| **7.** | **Visualizaci√≥n y An√°lisis** | Generaci√≥n de **Mapas de Atenci√≥n** comparativos (Est√°ndar vs. Diferencial) para analizar la **sparsidad** y la focalizaci√≥n en *tokens* relevantes. |
| **8.** | **Evaluaci√≥n Long-Context** | Comparaci√≥n del rendimiento y la estabilidad (tasa de alucinaci√≥n) de ambos modelos en escenarios de **contextos largos** (*Long-Context Evaluation*). |
| **9.** | **An√°lisis de Outliers** | Cuantificaci√≥n de la **reducci√≥n de activaciones extremas (outliers)** en las matrices de atenci√≥n y su correlaci√≥n con la mitigaci√≥n de alucinaciones. |
| **10.** | **M√©tricas de Evaluaci√≥n** | Detalle de las m√©tricas utilizadas: **Exact Match (EM)** y **ROUGE** para la fidelidad, y m√©tricas espec√≠ficas para medir la **atenci√≥n focalizada** y la tasa de alucinaci√≥n. |
| **11.** | **Conclusiones y Trabajo Futuro** | Resumen de los resultados clave, validaci√≥n de la hip√≥tesis, y propuesta de l√≠neas de investigaci√≥n futuras (ej. aplicaci√≥n a modelos LLM a gran escala). |

# Resultados Principales (Preliminares)

- Reducci√≥n significativa de atenci√≥n a tokens irrelevantes
- Disminuci√≥n de alucinaciones en contextos con distracci√≥n
- Patrones de atenci√≥n m√°s esparsos y focalizados
- Menor presencia de outliers en las activaciones
- Mejor rendimiento en tareas de "needle in a haystack" con contextos >8k tokens

# C√≥mo Ejecutar

Puedes abrir directamente en Google Colab:
Open In Colab
O clonar y ejecutar localmente:

git clone https://github.com/tu-usuario/differential-transformer-dcm.git
cd differential-transformer-dcm
jupyter notebook Differential_Transformer_DCM.ipynb

pip install torch transformers datasets rouge-score matplotlib seaborn

# Visualizaciones Destacadas

<img width="1544" height="990" alt="image" src="https://github.com/user-attachments/assets/9315780b-4b25-4779-a901-24301cf42d85" />
Mapa de atenci√≥n: Transformer est√°ndar (izq.) vs. Differential Transformer (der.)

# Licencia
Universidad Nacional de Colombia - Sede Medell√≠n
Departamento de F√≠sica ‚Äî Procesamiento de Lenguaje Natural con Transformers
